{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FY7CYRZSfs_4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8l3bXlNfeF4",
    "outputId": "11c13a2c-df56-4c77-d062-c80d5a60a5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34272, 207)\n",
      "                        773869     767541     767542     717447     717446  \\\n",
      "2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
      "2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n",
      "2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
      "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
      "\n",
      "                        717445  773062  767620     737529     717816  ...  \\\n",
      "2012-03-01 00:00:00  68.750000  65.125  67.125  59.625000  62.750000  ...   \n",
      "2012-03-01 00:05:00  68.111111  65.000  65.000  57.444444  63.333333  ...   \n",
      "2012-03-01 00:10:00  66.250000  64.500  64.250  63.875000  65.375000  ...   \n",
      "2012-03-01 00:15:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
      "2012-03-01 00:20:00   0.000000   0.000   0.000   0.000000   0.000000  ...   \n",
      "\n",
      "                        772167  769372     774204     769806  717590  \\\n",
      "2012-03-01 00:00:00  45.625000  65.500  64.500000  66.428571  66.875   \n",
      "2012-03-01 00:05:00  50.666667  69.875  66.666667  58.555556  62.000   \n",
      "2012-03-01 00:10:00  44.125000  69.000  56.500000  59.250000  68.125   \n",
      "2012-03-01 00:15:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
      "2012-03-01 00:20:00   0.000000   0.000   0.000000   0.000000   0.000   \n",
      "\n",
      "                        717592     717595     772168     718141  769373  \n",
      "2012-03-01 00:00:00  59.375000  69.000000  59.250000  69.000000  61.875  \n",
      "2012-03-01 00:05:00  61.111111  64.444444  55.888889  68.444444  62.875  \n",
      "2012-03-01 00:10:00  62.500000  65.625000  61.375000  69.857143  62.000  \n",
      "2012-03-01 00:15:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
      "2012-03-01 00:20:00   0.000000   0.000000   0.000000   0.000000   0.000  \n",
      "\n",
      "[5 rows x 207 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the HDF5 file using pandas\n",
    "df = pd.read_hdf('METR-LA.h5', key='df')\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUfOOT3hfwy7",
    "outputId": "affcc463-8649-41c1-8830-f57922ecc701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data shape: (34272, 207, 1)\n"
     ]
    }
   ],
   "source": [
    "data_np = df.values  # shape (time_steps, num_sensors)\n",
    "\n",
    "# Normalize, expand dims, etc.\n",
    "data_min = data_np.min()\n",
    "data_max = data_np.max()\n",
    "data_norm = (data_np - data_min) / (data_max - data_min)\n",
    "data_norm = data_norm[:, :, None]  # add feature dimension\n",
    "\n",
    "print(\"Normalized data shape:\", data_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wLztG1_sgxnJ",
    "outputId": "723ce91f-bcf0-45cd-b6e7-ea5fdc3fe99f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix shape: (207, 207)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('adj_METR-LA.pkl', 'rb') as f:\n",
    "    sensor_ids, sensor_id_to_ind, adj_mx = pickle.load(f, encoding='latin1')  # or 'bytes' for Py2 compatibility\n",
    "\n",
    "print(\"Adjacency matrix shape:\", adj_mx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zJwwbgDVg5E_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "history_len = 12   # input steps (1 hour)\n",
    "predict_len = 12   # output steps (1 hour)\n",
    "\n",
    "seq_len = history_len + predict_len\n",
    "\n",
    "num_samples = data_norm.shape[0]\n",
    "num_train = int(num_samples * 0.7)\n",
    "num_val = int(num_samples * 0.1)\n",
    "\n",
    "train_data = data_norm[:num_train]\n",
    "val_data = data_norm[num_train - seq_len:]\n",
    "test_data = data_norm[num_train + num_val - seq_len:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2B6eBy-hhgfP"
   },
   "outputs": [],
   "source": [
    "def generate_sequences(data, history_len=12, predict_len=12):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - history_len - predict_len):\n",
    "        x = data[i : i + history_len]\n",
    "        y = data[i + history_len : i + history_len + predict_len]\n",
    "        inputs.append(x)\n",
    "        targets.append(y)\n",
    "    return np.array(inputs), np.array(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geh78vSahwFo",
    "outputId": "90a3b2e9-7b5d-4964-edf1-5c65a2975cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (23966, 12, 207, 1), (23966, 12, 207, 1)\n",
      "Val:   (10282, 12, 207, 1), (10282, 12, 207, 1)\n",
      "Test:  (6855, 12, 207, 1), (6855, 12, 207, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = generate_sequences(train_data)\n",
    "x_val, y_val = generate_sequences(val_data)\n",
    "x_test, y_test = generate_sequences(test_data)\n",
    "\n",
    "print(f\"Train: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Val:   {x_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test:  {x_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5LW8n7lnhzc2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DCRNNDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Removed the print statement here\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "H69jzdY_i7Mp"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(DCRNNDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(DCRNNDataset(x_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(DCRNNDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOck7wr6litF"
   },
   "source": [
    "Step: Preprocess Adjacency Matrix (Diffusion Supports)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original Laplacian computation involved dense matrix multiplications using np.diag() and matrix products like D^(-1/2) * A * D^(-1/2), which caused the Jupyter kernel to crash due to high memory usage. This issue typically arises when processing even moderately sized graphs, especially in notebook environments or on GPUs with limited memory.\n",
    "\n",
    "How it was changed:\n",
    "To address this, we replaced the matrix multiplication with a more memory-efficient element-wise formulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_scaled_laplacian(adj):\n",
    "    \"\"\"\n",
    "    Compute the scaled symmetric normalized Laplacian.\n",
    "    This version avoids dense matrix multiplication and is memory-safe.\n",
    "    Method suggested by OpenAI.\n",
    "    \"\"\"\n",
    "    adj = adj.astype(np.float32)\n",
    "    n = adj.shape[0]\n",
    "    d = np.sum(adj, axis=1)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    d_inv_sqrt = np.zeros_like(d)\n",
    "    d_inv_sqrt[d > 0] = np.power(d[d > 0], -0.5)\n",
    "\n",
    "    # Element-wise Laplacian calculation: L = I - D^{-1/2} A D^{-1/2}\n",
    "    laplacian = np.eye(n, dtype=np.float32) - (d_inv_sqrt[:, None] * adj * d_inv_sqrt[None, :])\n",
    "    return laplacian\n",
    "\n",
    "def compute_diffusion_supports(adj_mx):\n",
    "    \"\"\"\n",
    "    Returns [forward_laplacian, reverse_laplacian] as torch tensors.\n",
    "    \"\"\"\n",
    "    forward = compute_scaled_laplacian(adj_mx)\n",
    "    reverse = compute_scaled_laplacian(adj_mx.T)\n",
    "\n",
    "    supports = [\n",
    "        torch.tensor(forward, dtype=torch.float32),\n",
    "        torch.tensor(reverse, dtype=torch.float32)\n",
    "    ]\n",
    "    return supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports = compute_diffusion_supports(adj_mx)\n",
    "\n",
    "# (optional) move to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "supports = [s.to(device) for s in supports]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOCEu759lvx6"
   },
   "source": [
    "Step 2: Diffusion Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "H0GWXoUulBke"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DiffusionConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, diffusion_steps, num_nodes):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        # The input to the MLP will be the concatenation of the initial input (x) and the results of the diffusion steps.\n",
    "        # The output shape of each diffusion step will be (batch_size, num_nodes, in_channels).\n",
    "        # There are 2 * diffusion_steps diffusion steps (forward and reverse) plus the initial input.\n",
    "        self.mlp = nn.Linear((diffusion_steps * 2 + 1) * in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x, supports):\n",
    "        \"\"\"\n",
    "        x: shape (batch_size, num_nodes, in_channels)\n",
    "        supports: list of precomputed diffusion matrices [forward, reverse], each (num_nodes, num_nodes)\n",
    "        \"\"\"\n",
    "        out = [x]  # 0-hop (identity)\n",
    "        # print(\"x shape before einsum:\", x.shape) # Debugging line removed\n",
    "\n",
    "        for support in supports:\n",
    "            x1 = x\n",
    "            for k in range(1, self.diffusion_steps + 1):\n",
    "                # The einsum equation \"nm,bmc->bnc\" is for multiplying a matrix (support, nm) with a batch of matrices (x1, bmc).\n",
    "                # support has shape (num_nodes, num_nodes) -> nm\n",
    "                # x1 has shape (batch_size, num_nodes, in_channels) -> bmc\n",
    "                # The output should have shape (batch_size, num_nodes, in_channels) -> bnc\n",
    "\n",
    "                x1 = torch.einsum(\"nm,bmc->bnc\", support, x1)\n",
    "                 # graph conv\n",
    "\n",
    "                out.append(x1)\n",
    "        x_cat = torch.cat(out, dim=-1)  # concat along features\n",
    "        return self.mlp(x_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "r0NUPRrIl-Ur"
   },
   "outputs": [],
   "source": [
    "class DCRNNCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, diffusion_steps, num_nodes):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_nodes = num_nodes\n",
    "\n",
    "        self.dc_xz = DiffusionConv(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "        self.dc_hz = DiffusionConv(hidden_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "\n",
    "        self.dc_xr = DiffusionConv(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "        self.dc_hr = DiffusionConv(hidden_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "\n",
    "        self.dc_xh = DiffusionConv(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "        self.dc_hh = DiffusionConv(hidden_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "\n",
    "    def forward(self, x, h, supports):\n",
    "        z = torch.sigmoid(self.dc_xz(x, supports) + self.dc_hz(h, supports))\n",
    "        r = torch.sigmoid(self.dc_xr(x, supports) + self.dc_hr(h, supports))\n",
    "        h_tilde = torch.tanh(self.dc_xh(x, supports) + self.dc_hh(r * h, supports))\n",
    "        h = (1 - z) * h + z * h_tilde\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DnpCxGLvmS8n"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DCRNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, diffusion_steps, num_nodes):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.cell = DCRNNCell(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "\n",
    "    def forward(self, inputs, hidden_state, supports):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, seq_len, num_nodes, input_dim)\n",
    "        hidden_state: (batch_size, num_nodes, hidden_dim)\n",
    "        supports: list of diffusion support matrices\n",
    "        \"\"\"\n",
    "        seq_len = inputs.shape[1]\n",
    "        h = hidden_state\n",
    "        for t in range(seq_len):\n",
    "            x_t = inputs[:, t, :, :]  # (batch, nodes, input_dim)\n",
    "            h = self.cell(x_t, h, supports)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miyI1w_KnT7c",
    "outputId": "5b9b7651-5a6c-489a-8ebf-19ec4f879a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([64, 207, 64])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "seq_len = 12\n",
    "num_nodes = 207\n",
    "input_dim = 1\n",
    "hidden_dim = 64\n",
    "diffusion_steps = 2\n",
    "\n",
    "encoder = DCRNNEncoder(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "\n",
    "# Initialize hidden state (zeros)\n",
    "h0 = torch.zeros(batch_size, num_nodes, hidden_dim)\n",
    "\n",
    "# Example input batch (random)\n",
    "x = torch.randn(batch_size, seq_len, num_nodes, input_dim)\n",
    "\n",
    "# supports is your list of diffusion matrices loaded earlier\n",
    "output_hidden = encoder(x, h0, supports)\n",
    "\n",
    "print(\"Encoder output shape:\", output_hidden.shape)  # (batch, nodes, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xpMWJN3HnbqP"
   },
   "outputs": [],
   "source": [
    "class DCRNNDecoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, diffusion_steps, num_nodes, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_nodes = num_nodes\n",
    "        self.cell = DCRNNCell(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "        self.projection = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, inputs, hidden_state, supports, target_len, targets=None, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        inputs: (batch_size, 1, num_nodes, input_dim) initial input (e.g., last known step)\n",
    "        hidden_state: (batch_size, num_nodes, hidden_dim) encoder hidden state\n",
    "        supports: list of diffusion support matrices\n",
    "        target_len: int, number of steps to predict\n",
    "        targets: (batch_size, target_len, num_nodes, output_dim) ground truth for teacher forcing (during training)\n",
    "        teacher_forcing_ratio: probability to use ground truth as next input during training\n",
    "\n",
    "        Returns:\n",
    "          outputs: (batch_size, target_len, num_nodes, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size = inputs.shape[0]\n",
    "        outputs = []\n",
    "        input_t = inputs  # first input to decoder (usually last observed step)\n",
    "\n",
    "        h = hidden_state\n",
    "        for t in range(target_len):\n",
    "            # Run one step of DCRNNCell\n",
    "            # input_t shape: (batch, 1, nodes, features) or (batch, nodes, features) if teacher forcing is off and using previous output\n",
    "            # Squeeze to remove the time dimension if it's present\n",
    "            input_to_cell = input_t.squeeze(1) if input_t.ndim == 4 else input_t\n",
    "            h = self.cell(input_to_cell, h, supports)  # input_to_cell shape: (batch, nodes, input_dim) or (batch, nodes, output_dim)\n",
    "            output = self.projection(h)  # (batch, nodes, output_dim)\n",
    "            outputs.append(output.unsqueeze(1))  # add time dimension\n",
    "\n",
    "            # Decide next input (teacher forcing)\n",
    "            if self.training and targets is not None and t < target_len -1 and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                # Use ground truth next step\n",
    "                input_t = targets[:, t:t+1, :, :] # shape (batch, 1, nodes, output_dim)\n",
    "            else:\n",
    "                # Use prediction as next input\n",
    "                input_t = output.unsqueeze(1) # shape (batch, 1, nodes, output_dim)\n",
    "\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Z-ZE0FQdo4uO"
   },
   "outputs": [],
   "source": [
    "class DCRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, diffusion_steps, num_nodes, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = DCRNNEncoder(input_dim, hidden_dim, diffusion_steps, num_nodes)\n",
    "        self.decoder = DCRNNDecoder(output_dim, hidden_dim, diffusion_steps, num_nodes, output_dim) # Decoder input_dim should be output_dim\n",
    "\n",
    "    def forward(self, source, target_len, supports, targets=None, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        source: (batch, seq_len, num_nodes, input_dim) - input sequence\n",
    "        target_len: int - number of time steps to predict\n",
    "        supports: list of adjacency-based diffusion matrices\n",
    "        targets: (batch, target_len, num_nodes, output_dim) - ground truth for teacher forcing (during training)\n",
    "        teacher_forcing_ratio: float [0,1] - probability to use ground truth in decoder during training\n",
    "\n",
    "        Returns:\n",
    "          outputs: (batch, target_len, num_nodes, output_dim)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, num_nodes, input_dim = source.shape\n",
    "\n",
    "        # Encode input sequence\n",
    "        h0 = torch.zeros(batch_size, num_nodes, self.encoder.hidden_dim, device=source.device)\n",
    "        encoder_hidden = self.encoder(source, h0, supports)\n",
    "\n",
    "        # Prepare initial decoder input: last observed time step\n",
    "        # Use the last step of the source sequence as the initial input to the decoder.\n",
    "        # Its shape should be (batch_size, 1, num_nodes, input_dim).\n",
    "        decoder_input = source[:, -1:, :, :]\n",
    "\n",
    "        # Decode to predict future steps\n",
    "        # Pass targets to the decoder if available (during training)\n",
    "        outputs = self.decoder(decoder_input, encoder_hidden, supports, target_len, targets, teacher_forcing_ratio)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukukxy48pOv-",
    "outputId": "edfa897d-d56c-4215-f370-52a20e9b6aec"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "hidden_dim = 64\n",
    "diffusion_steps = 2\n",
    "num_nodes = 207\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate model\n",
    "model = DCRNN(input_dim, hidden_dim, diffusion_steps, num_nodes, output_dim)\n",
    "model.train()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Assuming you have a device (e.g., GPU) set up\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "supports = [support.to(device) for support in supports]\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:  # from your DataLoader\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move to device if needed\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        # Forward pass: predict future traffic\n",
    "        # Pass batch_y to the model during training for teacher forcing\n",
    "        outputs = model(batch_x, target_len=batch_y.shape[1], supports=supports, targets=batch_y, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqXK1-MvuY2G"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
